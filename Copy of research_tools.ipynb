{"cells":[{"cell_type":"markdown","metadata":{"id":"xLOXFOT5Q40E"},"source":["##### Copyright 2020 The TensorFlow Authors."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"iiQkM5ZgQ8r2"},"outputs":[],"source":["#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."]},{"cell_type":"markdown","metadata":{"id":"j6331ZSsQGY3"},"source":["# Research tools"]},{"cell_type":"markdown","metadata":{"id":"i9Jcnb8bQQyd"},"source":["<table class=\"tfo-notebook-buttons\" align=\"left\">\n","  <td>\n","    <a target=\"_blank\" href=\"https://www.tensorflow.org/quantum/tutorials/research_tools\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/quantum/blob/master/docs/tutorials/research_tools.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://github.com/tensorflow/quantum/blob/master/docs/tutorials/research_tools.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n","  </td>\n","  <td>\n","    <a href=\"https://storage.googleapis.com/tensorflow_docs/quantum/docs/tutorials/research_tools.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n","  </td>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"tOpPugFsILnT"},"source":["TensorFlow Quantum brings quantum primitives into the TensorFlow ecosystem. Now quantum researchers can leverage tools from TensorFlow. In this tutorial you will take a closer look at incorporating [TensorBoard](https://www.tensorflow.org/tensorboard) into your quantum computing research. Using the [DCGAN tutorial](https://www.tensorflow.org/tutorials/generative/dcgan) from TensorFlow you will quickly build up working experiments and visualizations similar to ones done by [Niu et al.](https://arxiv.org/pdf/2010.11983.pdf). Broadly speaking you will:\n","\n","1. Train a GAN to produce samples that look like they came from quantum circuits.\n","2. Visualize the training progress as well as distribuion evolution over time.\n","3. Benchmark the experiment by exploring the compute graph."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yZvic4nmOH7v"},"outputs":[],"source":["!pip install tensorflow==2.15.0 tensorflow-quantum==0.7.3 tensorboard_plugin_profile==2.15.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Ql5PW-ACO0J"},"outputs":[],"source":["# Update package resources to account for version changes.\n","import importlib, pkg_resources\n","importlib.reload(pkg_resources)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"INxjZ39hzHLu"},"outputs":[],"source":["#docs_infra: no_execute\n","%load_ext tensorboard"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OVU9jSM80hvj"},"outputs":[],"source":["import datetime\n","import time\n","import cirq\n","import tensorflow as tf\n","import tensorflow_quantum as tfq\n","from tensorflow.keras import layers\n","\n","# visualization tools\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","from cirq.contrib.svg import SVGCircuit"]},{"cell_type":"markdown","metadata":{"id":"IYf7A1mubOfW"},"source":["## 1. Data generation\n","\n","Start by gathering some data. You can use TensorFlow Quantum to quickly generate some bitstring samples that will be the primary datasource for the rest of your experiments. Like Niu et al. you will explore how easy it is to emulate sampling from random circuits with drastically reduced depth. First, define some helpers:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1_6ayfdGbExV"},"outputs":[],"source":["def generate_circuit(qubits):\n","    \"\"\"Generate a random circuit on qubits.\"\"\"\n","    random_circuit = cirq.experiments.random_rotations_between_grid_interaction_layers_circuit(\n","        qubits, depth=2)\n","    return random_circuit\n","\n","def generate_data(circuit, n_samples):\n","    \"\"\"Draw n_samples samples from circuit into a tf.Tensor.\"\"\"\n","    return tf.squeeze(tfq.layers.Sample()(circuit, repetitions=n_samples).to_tensor())"]},{"cell_type":"markdown","metadata":{"id":"4BaTKnlMfJcW"},"source":["Now you can inspect the circuit as well as some sample data:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wpXMPpaCdMHs"},"outputs":[],"source":["qubits = cirq.GridQubit.rect(1, 5)\n","random_circuit_m = generate_circuit(qubits) + cirq.measure_each(*qubits)\n","SVGCircuit(random_circuit_m)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vswKr--Lfecp"},"outputs":[],"source":["samples = cirq.sample(random_circuit_m, repetitions=10)\n","print('10 Random bitstrings from this circuit:')\n","print(samples)"]},{"cell_type":"markdown","metadata":{"id":"DQ7Hkc87hO5m"},"source":["You can do the same thing in TensorFlow Quantum with:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lr35KSuehN7J"},"outputs":[],"source":["generate_data(random_circuit_m, 10)"]},{"cell_type":"markdown","metadata":{"id":"qjP1bEfkjFPz"},"source":["Now you can quickly generate your training data with:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c_vAWkZFc0g-"},"outputs":[],"source":["N_SAMPLES = 60000\n","N_QUBITS = 10\n","QUBITS = cirq.GridQubit.rect(1, N_QUBITS)\n","REFERENCE_CIRCUIT = generate_circuit(QUBITS)\n","all_data = generate_data(REFERENCE_CIRCUIT, N_SAMPLES)\n","all_data"]},{"cell_type":"markdown","metadata":{"id":"_aQ1MvuYmoGv"},"source":["It will be useful to define some helper functions to visualize as training gets underway. Two interesting quantities to use are:\n","1. The integer values of samples, so that you can create histograms of the distribution.\n","2. The [linear XEB](https://arxiv.org/pdf/1608.00263.pdf) fidelity estimate of a set of samples, to give some indication of how \"truly quantum random\" the samples are.\n","\n","Note: Since you are dealing with reduced depth random circuits XEB fidelity numbers may tend to vary from run to run."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MJakIECTbMd7"},"outputs":[],"source":["@tf.function\n","def bits_to_ints(bits):\n","    \"\"\"Convert tensor of bitstrings to tensor of ints.\"\"\"\n","    sigs = tf.constant([1 << i for i in range(N_QUBITS)], dtype=tf.int32)\n","    rounded_bits = tf.clip_by_value(tf.math.round(\n","        tf.cast(bits, dtype=tf.dtypes.float32)), clip_value_min=0, clip_value_max=1)\n","    return tf.einsum('jk,k->j', tf.cast(rounded_bits, dtype=tf.dtypes.int32), sigs)\n","\n","@tf.function\n","def xeb_fid(bits):\n","    \"\"\"Compute linear XEB fidelity of bitstrings.\"\"\"\n","    final_probs = tf.squeeze(\n","        tf.abs(tfq.layers.State()(REFERENCE_CIRCUIT).to_tensor()) ** 2)\n","    nums = bits_to_ints(bits)\n","    return (2 ** N_QUBITS) * tf.reduce_mean(tf.gather(final_probs, nums)) - 1.0"]},{"cell_type":"markdown","metadata":{"id":"tWj-bZHboXZI"},"source":["Here you can visualize your distribution and sanity check things using XEB:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9HFGMGLToVHu"},"outputs":[],"source":["plt.hist(bits_to_ints(all_data).numpy(), 50)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9m-PzaTMpB_H"},"outputs":[],"source":["xeb_fid(all_data)"]},{"cell_type":"markdown","metadata":{"id":"g79655cbZQLh"},"source":["## 2. Build a model\n","\n","Here you can use the relevant components from the [DCGAN tutorial](https://www.tensorflow.org/tutorials/generative/dcgan) for the quantum case. Instead of producing MNIST digits the new GAN will be used to produce bitstring samples with length `N_QUBITS`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FKFndGRszJSD"},"outputs":[],"source":["LATENT_DIM = 100\n","def make_generator_model():\n","    \"\"\"Construct generator model.\"\"\"\n","    model = tf.keras.Sequential()\n","    model.add(layers.Dense(256, use_bias=False, input_shape=(LATENT_DIM,)))\n","    model.add(layers.Dense(128, activation='relu'))\n","    model.add(layers.Dropout(0.3))\n","    model.add(layers.Dense(64, activation='relu'))\n","    model.add(layers.Dense(N_QUBITS, activation='relu'))\n","\n","    return model\n","\n","def make_discriminator_model():\n","    \"\"\"Constrcut discriminator model.\"\"\"\n","    model = tf.keras.Sequential()\n","    model.add(layers.Dense(256, use_bias=False, input_shape=(N_QUBITS,)))\n","    model.add(layers.Dense(128, activation='relu'))\n","    model.add(layers.Dropout(0.3))\n","    model.add(layers.Dense(32, activation='relu'))\n","    model.add(layers.Dense(1))\n","\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"793ddeeed493"},"source":["Next, instantiate your generator and discriminator models, define the losses and create the `train_step` function to use for your main training loop:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DWNFY37H0f2p"},"outputs":[],"source":["discriminator = make_discriminator_model()\n","generator = make_generator_model()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J3NxLYGb0gfo"},"outputs":[],"source":["cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n","def discriminator_loss(real_output, fake_output):\n","    \"\"\"Compute discriminator loss.\"\"\"\n","    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n","    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n","    total_loss = real_loss + fake_loss\n","    return total_loss\n","\n","def generator_loss(fake_output):\n","    \"\"\"Compute generator loss.\"\"\"\n","    return cross_entropy(tf.ones_like(fake_output), fake_output)\n","\n","generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n","discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c4YfBzfy08-c"},"outputs":[],"source":["BATCH_SIZE=256\n","\n","@tf.function\n","def train_step(images):\n","    \"\"\"Run train step on provided image batch.\"\"\"\n","    noise = tf.random.normal([BATCH_SIZE, LATENT_DIM])\n","    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n","        generated_images = generator(noise, training=True)\n","\n","        real_output = discriminator(images, training=True)\n","        fake_output = discriminator(generated_images, training=True)\n","\n","        gen_loss = generator_loss(fake_output)\n","        disc_loss = discriminator_loss(real_output, fake_output)\n","\n","    gradients_of_generator = gen_tape.gradient(\n","        gen_loss, generator.trainable_variables)\n","    gradients_of_discriminator = disc_tape.gradient(\n","        disc_loss, discriminator.trainable_variables)\n","\n","    generator_optimizer.apply_gradients(\n","        zip(gradients_of_generator, generator.trainable_variables))\n","    discriminator_optimizer.apply_gradients(\n","        zip(gradients_of_discriminator, discriminator.trainable_variables))\n","\n","    return gen_loss, disc_loss"]},{"cell_type":"markdown","metadata":{"id":"bb6f98ab4bf9"},"source":["Now that you have all the building blocks needed for your model, you can setup a training function that incorporates TensorBoard visualization. First setup a TensorBoard filewriter:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dJMnoal9HFM-"},"outputs":[],"source":["logdir = \"tb_logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","file_writer = tf.summary.create_file_writer(logdir + \"/metrics\")\n","file_writer.set_as_default()"]},{"cell_type":"markdown","metadata":{"id":"d4076c62f4f1"},"source":["Using the `tf.summary` module, you can now incorporate `scalar`, `histogram` (as well as other) logging to TensorBoard inside of the main `train` function:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rt4_0Dy_ENvv"},"outputs":[],"source":["def train(dataset, epochs, start_epoch=1):\n","    \"\"\"Launch full training run for the given number of epochs.\"\"\"\n","    # Log original training distribution.\n","    tf.summary.histogram('Training Distribution', data=bits_to_ints(dataset), step=0)\n","\n","    batched_data = tf.data.Dataset.from_tensor_slices(dataset).shuffle(N_SAMPLES).batch(512)\n","    t = time.time()\n","    for epoch in range(start_epoch, start_epoch + epochs):\n","        for i, image_batch in enumerate(batched_data):\n","            # Log batch-wise loss.\n","            gl, dl = train_step(image_batch)\n","            tf.summary.scalar(\n","                'Generator loss', data=gl, step=epoch * len(batched_data) + i)\n","            tf.summary.scalar(\n","                'Discriminator loss', data=dl, step=epoch * len(batched_data) + i)\n","\n","        # Log full dataset XEB Fidelity and generated distribution.\n","        generated_samples = generator(tf.random.normal([N_SAMPLES, 100]))\n","        tf.summary.scalar(\n","        'Generator XEB Fidelity Estimate', data=xeb_fid(generated_samples), step=epoch)\n","        tf.summary.histogram(\n","        'Generator distribution', data=bits_to_ints(generated_samples), step=epoch)\n","        # Log new samples drawn from this particular random circuit.\n","        random_new_distribution = generate_data(REFERENCE_CIRCUIT, N_SAMPLES)\n","        tf.summary.histogram(\n","        'New round of True samples', data=bits_to_ints(random_new_distribution), step=epoch)\n","\n","        if epoch % 10 == 0:\n","            print('Epoch {}, took {}(s)'.format(epoch, time.time() - t))\n","            t = time.time()"]},{"cell_type":"markdown","metadata":{"id":"4ceb5dc64798"},"source":["## 3. Vizualize training and performance\n","\n","The TensorBoard dashboard can now be launched with:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BYsJ2P1wE9yj"},"outputs":[],"source":["#docs_infra: no_execute\n","%tensorboard --logdir tb_logs/"]},{"cell_type":"markdown","metadata":{"id":"0ab7afeef60f"},"source":["When calling `train` the TensoBoard dashboard will auto-update with all of the summary statistics given in the training loop."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"__4b2wDREb5u"},"outputs":[],"source":["train(all_data, epochs=50)"]},{"cell_type":"markdown","metadata":{"id":"cee7fb4256a8"},"source":["While the training is running (and once it is complete) you can examine the scalar quantities:\n","\n","<img src=\"https://github.com/tensorflow/quantum/blob/master/docs/tutorials/images/visualize_1.png?raw=1\">\n","\n","Switching over to the histogram tab you can also see how well the generator network does at recreating samples from the quantum distribution:\n","\n","<img src=\"https://github.com/tensorflow/quantum/blob/master/docs/tutorials/images/visualize_2.png?raw=1\">"]},{"cell_type":"markdown","metadata":{"id":"aTtz2el1WpnW"},"source":["In addition to allowing real time monitoring of summary statistics related to your experiment, TensorBoard can also help you profile your experiments to identify performance bottlenecks. To re-run your model with performance monitoring you can do:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mRo04JwkW-p8"},"outputs":[],"source":["tf.profiler.experimental.start(logdir)\n","train(all_data, epochs=10, start_epoch=50)\n","tf.profiler.experimental.stop()"]},{"cell_type":"markdown","metadata":{"id":"83c4bf1f8abc"},"source":["TensorBoard will profile all of the code between `tf.profiler.experimental.start` and `tf.profiler.experimental.stop`. This profile data can then be viewed in the `profile` page of TensorBoard:\n","\n","<img src=\"https://github.com/tensorflow/quantum/blob/master/docs/tutorials/images/visualize_3.png?raw=1\">"]},{"cell_type":"markdown","metadata":{"id":"3wE7YILyinKy"},"source":["Success: You have now conducted and visualized an experiment using TensorFlow Quantum and TensorBoard.\n","\n","Try increasing the depth or experimenting with different classes of quantum circuits. Check out all the other great features of [TensorBoard](https://www.tensorflow.org/tensorboard) like [hyperparameter tuning](https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams) that you can incorporate into your TensorFlow Quantum experiments."]}],"metadata":{"colab":{"name":"research_tools.ipynb","toc_visible":true,"provenance":[{"file_id":"https://github.com/tensorflow/quantum/blob/master/docs/tutorials/research_tools.ipynb","timestamp":1719984539100}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}